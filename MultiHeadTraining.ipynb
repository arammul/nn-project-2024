{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/space/home/arammul/.conda/envs/nn-project/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import MultiDataset, GTA5Dataset, VistasDataset, CityscapesDataset, ADE20KDataset\n",
    "from dataloaders import collate_fn, MultiDatasetBatchSampler\n",
    "from models import MultiHeadUnet\n",
    "from epochs import MultiHeadTrainEpoch, MultiHeadValidEpoch\n",
    "from utils import get_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTA5_DATASET_IMAGES = \"/gpfs/space/home/arammul/datasets/GTA-images/images\"\n",
    "GTA5_DATASET_LABELS = \"/gpfs/space/home/arammul/datasets/GTA-images/labels\"\n",
    "\n",
    "VISTAS_BASE_PATH = \"/gpfs/space/home/arammul/datasets/vistas\"\n",
    "VISTAS_NUM_CLASSES = 124\n",
    "\n",
    "CITYSCAPES_IMAGES_BASE_PATH = \"/gpfs/space/home/arammul/datasets/cityscapes/leftImg8bit\"\n",
    "CITYSCAPES_LABELS_BASE_PATH = \"/gpfs/space/home/arammul/datasets/cityscapes/gtFine\"\n",
    "\n",
    "ADE20K_BASE_PATH = \"/gpfs/space/home/arammul/datasets/ade20k/ADE20K_2021_17_01/images/ADE\"\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATALOADER_NUM_WORKERS=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTA5_LABEL_TO_CLASS = {\n",
    "  0: 'unlabeled'           ,\n",
    "  1: 'ego vehicle'         ,\n",
    "  2: 'rectification border',\n",
    "  3: 'out of roi'          ,\n",
    "  4: 'static'              ,\n",
    "  5: 'dynamic'             ,\n",
    "  6: 'ground'              ,\n",
    "  7: 'road'                ,\n",
    "  8: 'sidewalk'            ,\n",
    "  9: 'parking'             ,\n",
    " 10: 'rail track'          ,\n",
    " 11: 'building'            ,\n",
    " 12: 'wall'                ,\n",
    " 13: 'fence'               ,\n",
    " 14: 'guard rail'          ,\n",
    " 15: 'bridge'              ,\n",
    " 16: 'tunnel'              ,\n",
    " 17: 'pole'                ,\n",
    " 18: 'polegroup'           ,\n",
    " 19: 'traffic light'       ,\n",
    " 20: 'traffic sign'        ,\n",
    " 21: 'vegetation'          ,\n",
    " 22: 'terrain'             ,\n",
    " 23: 'sky'                 ,\n",
    " 24: 'person'              ,\n",
    " 25: 'rider'               ,\n",
    " 26: 'car'                 ,\n",
    " 27: 'truck'               ,\n",
    " 28: 'bus'                 ,\n",
    " 29: 'caravan'             , \n",
    " 30: 'trailer'             , \n",
    " 31: 'train'               , \n",
    " 32: 'motorcycle'          , \n",
    " 33: 'bicycle'             , \n",
    " 34: 'license plate'       \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_configs = [\n",
    "    {\n",
    "        \"name\": \"GTA5\",\n",
    "        \"images_path\": GTA5_DATASET_IMAGES,\n",
    "        \"labels_path\": GTA5_DATASET_LABELS,\n",
    "        \"num_classes\": len(GTA5_LABEL_TO_CLASS),\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Vistas\",\n",
    "        \"num_classes\": VISTAS_NUM_CLASSES,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Cityscapes\",\n",
    "        \"num_classes\": 19,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ADE20K\",\n",
    "        \"num_classes\": 100,\n",
    "    }\n",
    "]\n",
    "\n",
    "for config in [dataset_configs[0]]:\n",
    "    image_files = sorted(os.listdir(config[\"images_path\"]))\n",
    "    image_files = [path for path in image_files if path.endswith('.png')]\n",
    "    image_files = get_subset(image_files, 0.4)\n",
    "    \n",
    "    config[\"image_files\"] = image_files\n",
    "\n",
    "    X_train_val, X_test = train_test_split(image_files, test_size=0.1, random_state=42)\n",
    "    X_train, X_val = train_test_split(X_train_val, test_size=0.1111, random_state=42)\n",
    "\n",
    "    config[\"X_train\"] = X_train\n",
    "    config[\"X_val\"] = X_val\n",
    "    config[\"X_test\"] = X_test\n",
    "\n",
    "for config in [dataset_configs[3]]:\n",
    "    image_files = ADE20KDataset.get_image_files(f\"{ADE20K_BASE_PATH}/training/\")\n",
    "    image_files = get_subset(image_files, 0.4)\n",
    "    \n",
    "    X_train, X_val = train_test_split(image_files, test_size=0.1, random_state=42)\n",
    "    config[\"X_train\"] = X_train\n",
    "    config[\"X_val\"] = X_val\n",
    "    image_files_test = ADE20KDataset.get_image_files(f\"{ADE20K_BASE_PATH}/validation/\")\n",
    "    config[\"X_test\"] = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_1 = GTA5Dataset(\n",
    "#     dataset_name=\"gta5_1\",\n",
    "#     image_dir=dataset_configs[0][\"images_path\"], \n",
    "#     label_dir=dataset_configs[0][\"labels_path\"],\n",
    "#     image_files=dataset_configs[0][\"X_train\"],\n",
    "#     num_classes=len(GTA5_LABEL_TO_CLASS),\n",
    "#     resize_dims=(526, 957), \n",
    "#     crop_dims=(512, 512)\n",
    "# )\n",
    "\n",
    "# dataset_2 = GTA5Dataset(\n",
    "#     dataset_name=\"gta5_2\",\n",
    "#     image_dir=dataset_configs[1][\"images_path\"], \n",
    "#     label_dir=dataset_configs[1][\"labels_path\"],\n",
    "#     image_files=dataset_configs[1][\"X_train\"],\n",
    "#     num_classes=len(GTA5_LABEL_TO_CLASS),\n",
    "#     resize_dims=(526, 957), \n",
    "#     crop_dims=(512, 512)\n",
    "# )\n",
    "\n",
    "# datasets = [dataset_1, dataset_2]\n",
    "# multi_dataset = MultiDataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_sampler = MultiDatasetBatchSampler(datasets, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = DataLoader(\n",
    "#     dataset=multi_dataset,\n",
    "#     batch_sampler=batch_sampler,\n",
    "#     collate_fn=collate_fn,\n",
    "#     num_workers=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'resnet101'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiHeadUnet(\n",
    "    dataset_configs=dataset_configs,\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_1 = GTA5Dataset(\n",
    "    dataset_name=\"GTA5\",\n",
    "    image_dir=dataset_configs[0][\"images_path\"], \n",
    "    label_dir=dataset_configs[0][\"labels_path\"],\n",
    "    image_files=dataset_configs[0][\"X_train\"],\n",
    "    num_classes=dataset_configs[0][\"num_classes\"],\n",
    "    preprocessing_fn=preprocessing_fn,\n",
    "    resize_dims=(526, 957), \n",
    "    crop_dims=(512, 512)\n",
    ")\n",
    "\n",
    "train_dataset_2 = VistasDataset(\n",
    "    dataset_name=\"Vistas\",\n",
    "    image_dir=VISTAS_BASE_PATH + \"/training/images/\", \n",
    "    label_dir=VISTAS_BASE_PATH + \"/training/v2.0/labels/\",\n",
    "    image_files=get_subset(sorted(os.listdir(VISTAS_BASE_PATH + \"/training/images/\")), 0.4),\n",
    "    num_classes=VISTAS_NUM_CLASSES,\n",
    "    preprocessing_fn=preprocessing_fn,\n",
    "    downscale_to_height = 512,\n",
    "    crop_dims=(512, 512)\n",
    ")\n",
    "\n",
    "train_dataset_3 = CityscapesDataset(\n",
    "    dataset_name = \"Cityscapes\",\n",
    "    image_dir = f\"{CITYSCAPES_IMAGES_BASE_PATH}/train/\", \n",
    "    label_dir = f\"{CITYSCAPES_LABELS_BASE_PATH}/train/\", \n",
    "    image_files = CityscapesDataset.get_image_files(f\"{CITYSCAPES_IMAGES_BASE_PATH}/train/\"), \n",
    "    preprocessing_fn=preprocessing_fn,\n",
    "    downscale_to_height=512,\n",
    "    crop_dims=(512, 512)\n",
    ")\n",
    "\n",
    "train_dataset_4 = ADE20KDataset(\n",
    "    dataset_name = \"ADE20K\",\n",
    "    image_dir = f\"{ADE20K_BASE_PATH}/training/\", \n",
    "    label_dir = f\"{ADE20K_BASE_PATH}/training/\", \n",
    "    image_files = dataset_configs[0][\"X_train\"], \n",
    "    preprocessing_fn=preprocessing_fn,\n",
    "    downscale_to_height=512,\n",
    "    crop_dims=(512, 512)\n",
    ")\n",
    "\n",
    "train_datasets = [train_dataset_1, train_dataset_2, train_dataset_3, train_dataset_4]\n",
    "train_multi_dataset = MultiDataset(train_datasets)\n",
    "train_batch_sampler = MultiDatasetBatchSampler(train_datasets, batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_dataset_1 = GTA5Dataset(\n",
    "    dataset_name=\"GTA5\",\n",
    "    image_dir=dataset_configs[0][\"images_path\"], \n",
    "    label_dir=dataset_configs[0][\"labels_path\"],\n",
    "    image_files=dataset_configs[0][\"X_val\"],\n",
    "    num_classes=dataset_configs[0][\"num_classes\"],\n",
    "    preprocessing_fn=preprocessing_fn,\n",
    "    resize_dims=(526, 957), \n",
    "    crop_dims=(512, 512)\n",
    ")\n",
    "\n",
    "valid_dataset_2 = VistasDataset(\n",
    "    dataset_name=\"Vistas\",\n",
    "    image_dir=VISTAS_BASE_PATH + \"/validation/images/\", \n",
    "    label_dir=VISTAS_BASE_PATH + \"/validation/v2.0/labels/\",\n",
    "    image_files=get_subset(sorted(os.listdir(VISTAS_BASE_PATH + \"/validation/images/\")), 0.4),\n",
    "    num_classes=VISTAS_NUM_CLASSES,\n",
    "    downscale_to_height = 512,\n",
    "    preprocessing_fn=preprocessing_fn,\n",
    "    crop_dims=(512, 512)\n",
    ")\n",
    "\n",
    "valid_dataset_3 = CityscapesDataset(\n",
    "    dataset_name = \"Cityscapes\",\n",
    "    image_dir = f\"{CITYSCAPES_IMAGES_BASE_PATH}/val/\", \n",
    "    label_dir = f\"{CITYSCAPES_LABELS_BASE_PATH}/val/\", \n",
    "    image_files = CityscapesDataset.get_image_files(f\"{CITYSCAPES_IMAGES_BASE_PATH}/val/\"), \n",
    "    preprocessing_fn=preprocessing_fn,\n",
    "    downscale_to_height=512,\n",
    "    crop_dims=(512, 512)\n",
    ")\n",
    "\n",
    "valid_dataset_4 = ADE20KDataset(\n",
    "    dataset_name = \"ADE20K\",\n",
    "    image_dir = f\"{ADE20K_BASE_PATH}/validation/\", \n",
    "    label_dir = f\"{ADE20K_BASE_PATH}/validation/\", \n",
    "    image_files = dataset_configs[0][\"X_val\"], \n",
    "    preprocessing_fn=preprocessing_fn,\n",
    "    downscale_to_height=512,\n",
    "    crop_dims=(512, 512)\n",
    ")\n",
    "\n",
    "valid_datasets = [valid_dataset_1, valid_dataset_2, valid_dataset_3, valid_dataset_4]\n",
    "valid_multi_dataset = MultiDataset(valid_datasets)\n",
    "valid_batch_sampler = MultiDatasetBatchSampler(valid_datasets, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26151"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(d) for d in train_datasets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[999, 800, 500, 999]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(d) for d in valid_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_multi_dataset,\n",
    "    batch_sampler=train_batch_sampler,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=DATALOADER_NUM_WORKERS\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_multi_dataset,\n",
    "    batch_sampler=valid_batch_sampler,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=DATALOADER_NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = utils.losses.DiceLoss(activation='softmax2d')\n",
    "metrics = [\n",
    "    utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.001),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = MultiHeadTrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = MultiHeadValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "train:   2%| | 35/1634 [08:29<6:27:54, 14.56s/it, dice_loss - 0.2135, iou_score \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, NUM_EPOCHS):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i))\n\u001b[0;32m----> 6\u001b[0m     train_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     valid_logs \u001b[38;5;241m=\u001b[39m valid_epoch\u001b[38;5;241m.\u001b[39mrun(valid_loader)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_score \u001b[38;5;241m<\u001b[39m valid_logs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miou_score\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/NN-Project/epochs.py:29\u001b[0m, in \u001b[0;36mMultiHeadEpoch.run\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name, mini_batch \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     28\u001b[0m     batch[dataset_name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m mini_batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 29\u001b[0m     batch[dataset_name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmini_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m loss, predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_update(batch)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# update loss logs\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "max_score = 0\n",
    "for i in range(0, NUM_EPOCHS):\n",
    "    \n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    \n",
    "    if max_score < valid_logs['iou_score']:\n",
    "        max_score = valid_logs['iou_score']\n",
    "        torch.save(model, './best_model-4-datasets.pth')\n",
    "        print('Model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
